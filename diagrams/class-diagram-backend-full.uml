@startuml
class CameraCollection {
    - cameras: List[Camera]
    - camera_utils: CameraUtils
    + combine_images_to_video(fps: int)
    + generate_report()
}

class CameraUtils {
    - heatmap_alpha: int
    - output_dir: str
    - upsampling_factor: int
    - color_map: int
    + correct_fisheye_distortion(image: np.ndarray, distortionParameter: float): np.ndarray
    + correct_perspective(matrix: np.ndarray, corner_matrix: np.ndarray): np.ndarray
    + downsample_image(matrix: np.ndarray, scale_factor: int): np.ndarray
    + upsample_image(matrix: np.ndarray): np.ndarray
    + make_heatmap(matrix: np.ndarray): np.ndarray
    + add_graphics(picture: np.ndarray, count: int): np.ndarray
}

class Camera {
    - video_path: str
    - local_coordinates: List[Tuple[int, int]]
    - global_coordinates: List[Tuple[int, int]]
    - model: torch.nn.Module
    - frame_interval: int
    - batch_size: int
    - log_parameter: int
    - camera_utils: CameraUtils
    - distortion_parameters: Optional[float]
    - predicted_counts: List[float]
    - images: List[np.ndarray]
    + get_video_dataloader(): DataLoader
    + predict()
}

class Model {
    - block_size: int
    - model: torch.nn.Module
    + get_model(): torch.nn.Module
}

class VideoFrameDataset {
    - video_path: str
    - cap: cv2.VideoCapture
    - transform: Optional[Callable]
    - frame_interval: int
    - target_resolution: Tuple[int, int]
    - total_frames: int
    + __len__(): int
    + __getitem__(idx: int): torch.Tensor
    + __del__()
}

VideoFrameDataset --|> torch.utils.data.Dataset

CameraCollection "1" *-- "1" CameraUtils : has
CameraCollection "1" *-- "*" Camera : contains
Camera "1" *-- "1" CameraUtils : uses
Camera "1" *-- "1" Model : uses
Camera "1" *-- "1" VideoFrameDataset : uses
@enduml